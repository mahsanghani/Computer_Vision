# -*- coding: utf-8 -*-
"""yolov7-openvino.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZafk7MoG1Axr87E4XSNH4rAMeULZhCB

# How to Run Inference on YOLOv7 with Native Pytorch and OpenVINO™ Torch-ORT

This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows evaluation on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together. 

### **Accompanying Blog Post**

We recommend that you follow along in this notebook while reading the blog post: [Accelerate PyTorch Models via OpenVINO™ Integration with Torch-ORT](https://blog.roboflow.com/accelerate-pytorch-openvino-torch-ort/)
<br>



### **Custom Dataset**

Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset.


If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.


### **Steps Covered in this Tutorial**

To run the inference on a test image we take the following steps:

* Evaluate YOLOv7 performance with Native Pytorch
* Evaluate YOLOv7 performance with OpenVINO™ integration with Torch-ORT

OPTIONAL:
* Reparameterize for Inference 
* Deployment
* Active Learning

#Install Dependencies

_(Remember to choose None in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> None)_

Reminder, uploaded files will get deleted when this runtime is recycled.
"""

# Commented out IPython magic to ensure Python compatibility.
# Download YOLOv7 repository from Roboflow-ai and install requirements
!git clone https://github.com/roboflow-ai/yolov7.git
# %cd yolov7
!pip install -r requirements.txt

!pip install torch==1.12.1

"""# Download Correctly Formatted Custom Data

Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.
"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="0a4WwzoVWX7OLQHdybod")
project = rf.workspace("a-s").project("uwh")
dataset = project.version(6).download("yolov7")

"""# Bring your own retrained model

If you have [retrained your yolov7 model on a custom dataset](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/) from the Roboflow Universe, follow the steps in this section. 


**Note:** If you do not have retrained model, you can skip this section and use the pretrained model from ***content/yolov7/runs/best.pt***
"""

# Mount your google drive to access the pretrained model obtained from https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial 

from google.colab import drive
drive.mount('/content/gdrive')

"""# Evaluation

We can evaluate the performance of our custom training using the provided evalution script.

# Evaluate YOLOv7 performance with Native Pytorch

Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).

There are 2 minor changes we've made to run "detect.py" on CPU:
1.  We have commented out lines 38 and 39 in detect.py as the code is using [jit trace](https://pytorch.org/docs/stable/generated/torch.jit.trace.html).
2. Added lines 84 and 85 to enable device type as "cpu"
"""

# If you DO NOT have a retrained model, use this command to run evaluation with the provided trained model: 

!python detect_without_jit.py \
 --weights /content/yolov7/runs/best.pt \
 --conf 0.25 \
 --img-size 640 \
 --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg

"""Refer to "Display Inference on test image" section to display the saved image."""

# Run evaluation on a sample image with a retrained model

!python detect_without_jit.py \
 --weights /content/gdrive/MyDrive/TrainedModel/best.pt \
 --conf 0.25 \
 --img-size 640 \
 --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg

"""# Display inference on test image"""

#display inference on a sample image

import glob
from IPython.display import Image, display

i = 0
limit = 10000 # max images to print
# Change the path below according to the location where result image is saved.
for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG. 
    if i < limit:
      display(Image(filename=imageName))
      print("\n")
    i = i + 1

"""# Evaluate YOLOv7 performance with OpenVINO™ integration with Torch-ORT"""

# Install torch-ort-infer 
!pip install torch-ort-infer

"""Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).

Here, we added just 2 lines of code to boost performance with OpenVINO™ Torch-ORT

  line 17: from torch_ort import ORTInferenceModule

  line 71: model = ORTModule(model)   
"""

# If you DO NOT have a retrained model, use this command to run evaluation using the provided trained model: 
!python detect_ort.py \
 --weights /content/yolov7/runs/best.pt \
 --conf 0.25 \
 --img-size 640 \
 --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg

# Run evaluation on a sample image with a retrained model 

!python detect_ort.py \
 --weights /content/gdrive/MyDrive/TrainedModel/best.pt \
 --conf 0.25 \
 --img-size 640 \
 --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg

"""# Display inference on test image"""

#display inference on sample image

import glob
from IPython.display import Image, display

i = 0
limit = 10000 # max images to print
for imageName in glob.glob('/content/yolov7/runs/detect/exp2/*.jpg'): #assuming JPG
    if i < limit:
      display(Image(filename=imageName))
      print("\n")
    i = i + 1

"""# Performance Boost with OpenVINO™ integration with TORCH-ORT

You may calculate the performance boost with OpenVINO™ integration with TORCH-ORT as compared to Native Pytorch using the formula:
<br>
</br>

PERFORMANCE BOOST (%) = 
(inference time with native pytorch - inference time with T-ORT / inference time with native pytorch) * 100

# Next steps

Congratulations, you've ran inference on the YOLOv7 model!
<br>
 Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild.
"""