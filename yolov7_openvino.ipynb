{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# How to Run Inference on YOLOv7 with Native Pytorch and OpenVINOâ„¢ Torch-ORT\n",
        "\n",
        "This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows evaluation on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together. \n",
        "\n",
        "### **Accompanying Blog Post**\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post: [Accelerate PyTorch Models via OpenVINOâ„¢ Integration with Torch-ORT](https://blog.roboflow.com/accelerate-pytorch-openvino-torch-ort/)\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "### **Custom Dataset**\n",
        "\n",
        "Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset.\n",
        "\n",
        "\n",
        "If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n",
        "\n",
        "\n",
        "### **Steps Covered in this Tutorial**\n",
        "\n",
        "To run the inference on a test image we take the following steps:\n",
        "\n",
        "* Evaluate YOLOv7 performance with Native Pytorch\n",
        "* Evaluate YOLOv7 performance with OpenVINOâ„¢ integration with Torch-ORT\n",
        "\n",
        "OPTIONAL:\n",
        "* Reparameterize for Inference \n",
        "* Deployment\n",
        "* Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose None in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> None)_\n",
        "\n",
        "Reminder, uploaded files will get deleted when this runtime is recycled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nD-uPyQ_2jiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304a065c-ea33-4436-aa87-434d15f242fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov7' already exists and is not an empty directory.\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (1.12.1)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (4.65.0)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (2.12.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n",
            "Collecting torch!=1.12.0,>=1.7.0\n",
            "  Using cached torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.4.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.2.10.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (67.7.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (16.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.53.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.38)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (2.14.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.18.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.4.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1\n",
            "    Uninstalling torch-1.12.1:\n",
            "      Successfully uninstalled torch-1.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch-ort-infer 1.13.1 requires torch==1.12.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 repository from Roboflow-ai and install requirements\n",
        "!git clone https://github.com/roboflow-ai/yolov7.git\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.1"
      ],
      "metadata": {
        "id": "BOPOoHDKXsPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811dabeb-be43-4f96-d419-2fe8229edc2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.12.1\n",
            "  Using cached torch-1.12.1-cp39-cp39-manylinux1_x86_64.whl (776.4 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Correctly Formatted Custom Data\n",
        "\n",
        "Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot."
      ],
      "metadata": {
        "id": "hu5w7F936rzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"0a4WwzoVWX7OLQHdybod\")\n",
        "project = rf.workspace(\"a-s\").project(\"uwh\")\n",
        "dataset = project.version(6).download(\"yolov7\")"
      ],
      "metadata": {
        "id": "kKvnUnL1hCtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274997c4-cfcb-4b5f-f71e-fe71eb2a7787"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.9/dist-packages (1.0.5)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.26.15)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.9/dist-packages (from roboflow) (0.10.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.15.0)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in UWH-6 to yolov7pytorch: 100% [328109039 / 328109039] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to UWH-6 in yolov7pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1874/1874 [00:01<00:00, 1390.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bring your own retrained model\n",
        "\n",
        "If you have [retrained your yolov7 model on a custom dataset](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/) from the Roboflow Universe, follow the steps in this section. \n",
        "\n",
        "\n",
        "**Note:** If you do not have retrained model, you can skip this section and use the pretrained model from ***content/yolov7/runs/best.pt***"
      ],
      "metadata": {
        "id": "77kUgBxOMJWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your google drive to access the pretrained model obtained from https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "cdfV0L6DK1S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c55891-f7a4-4647-f903-91f42aa45a1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script."
      ],
      "metadata": {
        "id": "oti8hk4qbZ2e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Evaluate YOLOv7 performance with Native Pytorch\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).\n",
        "\n",
        "There are 2 minor changes we've made to run \"detect.py\" on CPU:\n",
        "1.  We have commented out lines 38 and 39 in detect.py as the code is using [jit trace](https://pytorch.org/docs/stable/generated/torch.jit.trace.html).\n",
        "2. Added lines 84 and 85 to enable device type as \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you DO NOT have a retrained model, use this command to run evaluation with the provided trained model: \n",
        "\n",
        "!python detect_without_jit.py \\\n",
        " --weights /content/yolov7/runs/best.pt \\\n",
        " --conf 0.25 \\\n",
        " --img-size 640 \\\n",
        " --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg"
      ],
      "metadata": {
        "id": "J-elO8XZRfgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75ee249-e62c-4709-b822-2b7321bca707"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.9/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "Namespace(weights=['/content/yolov7/runs/best.pt'], source='UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ 3cf1e25 torch 1.12.1+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36514136 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/detect_without_jit.py\", line 199, in <module>\n",
            "    detect()\n",
            "  File \"/content/yolov7/detect_without_jit.py\", line 93, in detect\n",
            "    pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
            "  File \"/content/yolov7/utils/general.py\", line 684, in non_max_suppression\n",
            "    i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torchvision/ops/boxes.py\", line 40, in nms\n",
            "    _assert_has_ops()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torchvision/extension.py\", line 48, in _assert_has_ops\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to \"Display Inference on test image\" section to display the saved image."
      ],
      "metadata": {
        "id": "BNxYGxWXTexe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N4cfnLtTCIce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37685687-bee8-4826-8f19-a53978db1e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.9/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "Namespace(weights=['/content/gdrive/MyDrive/TrainedModel/best.pt'], source='UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ 3cf1e25 torch 1.12.1+cu102 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/detect_without_jit.py\", line 199, in <module>\n",
            "    detect()\n",
            "  File \"/content/yolov7/detect_without_jit.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "  File \"/content/yolov7/models/experimental.py\", line 252, in attempt_load\n",
            "    ckpt = torch.load(w, map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 699, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/TrainedModel/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation on a sample image with a retrained model\n",
        "\n",
        "!python detect_without_jit.py \\\n",
        " --weights /content/gdrive/MyDrive/TrainedModel/best.pt \\\n",
        " --conf 0.25 \\\n",
        " --img-size 640 \\\n",
        " --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display inference on test image"
      ],
      "metadata": {
        "id": "-EFRk-NZ0F9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on a sample image\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "# Change the path below according to the location where result image is saved.\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG. \n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "Aj9zVFvv0CXh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate YOLOv7 performance with OpenVINOâ„¢ integration with Torch-ORT"
      ],
      "metadata": {
        "id": "tbfcIynofgEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch-ort-infer \n",
        "!pip install torch-ort-infer"
      ],
      "metadata": {
        "id": "D9yA1Vw-fTR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3254653-4fea-4919-ff0b-f84c1a4edf8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-ort-infer in /usr/local/lib/python3.9/dist-packages (1.13.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.9/dist-packages (from torch-ort-infer) (1.12.1)\n",
            "Requirement already satisfied: onnxruntime-openvino>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from torch-ort-infer) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1->torch-ort-infer) (4.5.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (15.0.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (23.3.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (1.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime-openvino>=1.12.0->torch-ort-infer) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime-openvino>=1.12.0->torch-ort-infer) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime-openvino>=1.12.0->torch-ort-infer) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).\n",
        "\n",
        "Here, we added just 2 lines of code to boost performance with OpenVINOâ„¢ Torch-ORT\n",
        "\n",
        "  line 17: from torch_ort import ORTInferenceModule\n",
        "\n",
        "  line 71: model = ORTModule(model)   "
      ],
      "metadata": {
        "id": "4LXuh0iFwi9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you DO NOT have a retrained model, use this command to run evaluation using the provided trained model: \n",
        "!python detect_ort.py \\\n",
        " --weights /content/yolov7/runs/best.pt \\\n",
        " --conf 0.25 \\\n",
        " --img-size 640 \\\n",
        " --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg"
      ],
      "metadata": {
        "id": "w6Vbr581Rzk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870527de-5e8c-4f69-e00d-ef3ffa0f9d96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.9/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/detect_ort.py\", line 17, in <module>\n",
            "    from torch_ort import ORTInferenceModule\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch_ort/__init__.py\", line 6, in <module>\n",
            "    from onnxruntime.training.ortmodule import DebugOptions, LogLevel\n",
            "ModuleNotFoundError: No module named 'onnxruntime.training'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation on a sample image with a retrained model \n",
        "\n",
        "!python detect_ort.py \\\n",
        " --weights /content/gdrive/MyDrive/TrainedModel/best.pt \\\n",
        " --conf 0.25 \\\n",
        " --img-size 640 \\\n",
        " --source UWH-6/test/images/DJI_0021_mp4-32_jpg.rf.0d9b746d8896d042b55a14c8303b4f36.jpg"
      ],
      "metadata": {
        "id": "euztwieogyNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79da6842-9bc7-434b-d1e4-7ef249a975ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.9/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/detect_ort.py\", line 17, in <module>\n",
            "    from torch_ort import ORTInferenceModule\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch_ort/__init__.py\", line 6, in <module>\n",
            "    from onnxruntime.training.ortmodule import DebugOptions, LogLevel\n",
            "ModuleNotFoundError: No module named 'onnxruntime.training'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display inference on test image"
      ],
      "metadata": {
        "id": "abv93C9c0ZkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on sample image\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp2/*.jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "2Y3gFh8d0bja"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Boost with OpenVINOâ„¢ integration with TORCH-ORT\n",
        "\n",
        "You may calculate the performance boost with OpenVINOâ„¢ integration with TORCH-ORT as compared to Native Pytorch using the formula:\n",
        "<br>\n",
        "</br>\n",
        "\n",
        "PERFORMANCE BOOST (%) = \n",
        "(inference time with native pytorch - inference time with T-ORT / inference time with native pytorch) * 100\n"
      ],
      "metadata": {
        "id": "Qo59uBcTMTk2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "Congratulations, you've ran inference on the YOLOv7 model!\n",
        "<br>\n",
        " Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}